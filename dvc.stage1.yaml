vars:
  - stage: base
  - baselanguages: "en de es fr it"
  - baselanguages_list: ["en", "de", "es", "fr", "it"]
  - clwepivot: "en"
  - embdim: 300
  - model: "continuous"
  - baseconfig: "train-base"

stages:
  #download_embeddings:
  #  cmd: download_embeddings "${baselanguages}"
  #  deps:
  #  - "/dev/null"
  #  outs:
  #  - "embeddings/models/"
  download_embeddings:
    desc: "Download the pre-trained fastText embeddings for our base languages"
    foreach: ${baselanguages_list}
    do:
      cmd: download_embeddings "${item}"
      wdir: "embeddings/models"
      deps: []
      outs:
      - "cc.${item}.${embdim}.vec"
      - "cc.${item}.${embdim}.bin"

  compute_alignments:
    desc: "Compute the alignments between each of the base languages and the chosen pivot"
    cmd: compute_alignments "${clwepivot}" "${baselanguages}"
    wdir: "embeddings"
    deps:
    - "models/"
    outs:
    - "dicts/"
    - "align/"

  extract_data:
    desc: "Extract the data TSVs from the data TAR archive and extract individual languages into separate files"
    cmd: extract_data "${baselanguages}"
    wdir: "data"
    deps:
    - "ted_talks.tar.gz"
    outs:
    - "extracted/"

  prepare_parallel_data:
    desc: "Prepare parallel data for each pair of base languages. We use this for training and evaluating the pre-trained model."
    cmd: prepare_parallel_data "train dev test" "${baselanguages}"
    wdir: "data"
    deps:
    - "extracted/"
    outs:
    - "parallel/"

  prepare_monolingual_data:
    desc: "Prepare monolingual data for each base language. Only used for building the embeddings (see `build_embeddings` stage)"
    cmd: prepare_monolingual_data "${baselanguages}"
    wdir: "data"
    deps:
    - "extracted/"
    outs:
    - "monolingual/"

  generate_specials:
    desc: "Generates random vectors for special vocabulary entries (<bland>, <unk>, ..., #en#, #de#, ...)"
    cmd: generate-specials.py "${embdim}" ${baselanguages} > "specials.vec"
    wdir: "data"
    deps: []
    outs:
    - "specials.vec"

  build_embeddings:
    desc: "Extract unique tokens from the monolingual corpora and build the embedding table for each language (in .vec format)"
    cmd: build_embeddings "${baselanguages}"
    deps:
    #- "extract-words.py"
    - "data/monolingual/"
    - "embeddings/align/"
    - "embeddings/models/"
    outs:
    - "data/embeddings/"

  build_basesystem_embeddings:
    desc: "Concatenate the embedding tables of each of the base languages"
    cmd: build_basesystem_embeddings "${baselanguages}"
    wdir: "data"
    deps:
    - "embeddings/"
    - "specials.vec"
    outs:
    - "vocab/"
    # XXX concatenated embeddings, change name
    - "allembeddings/"

  concat_data:
    desc: "Concatenate the parallel data to build our multilingual corpus"
    cmd: concat_data "${stage}" "${baselanguages}" "${baselanguages}"
    wdir: "data"
    deps:
    - "parallel/"
    outs:
    - "corpus/"

  preprocess:
    desc: "Call `onmt_preprocess` to binarize the training corpus"
    cmd: preprocess "${stage}"
    deps:
    - "data/corpus/train.${stage}.src"
    - "data/corpus/train.${stage}.tgt"
    - "data/corpus/dev.${stage}.src"
    - "data/corpus/dev.${stage}.tgt"
    - "data/vocab/"
    - "data/allembeddings/"
    outs:
    - "saves/${stage}/"

  train:
    desc: "Train the base model on supervised directions"
    cmd: train "${stage}" "${model}" "${baseconfig}"
    deps:
    - "saves/${stage}/"
    outs:
    - "models/${stage}/"
    metrics:
    - "logs/${stage}/"

  average_models:
    desc: "Average training checkpoints"
    cmd: onmt_average_models -m models/${stage}/*.pt -o models/${stage}_avg.pt
    deps:
    - "models/${stage}/"
    outs:
    - "models/${stage}_avg.pt"

  evauate_bleu:
    desc: "Evaluate translation scores on supervised directions"
    cmd: evauate_bleu "${stage}" "${baselanguages}" "${baselanguages}"
    deps:
    - "models/${stage}_avg.pt"
    #- "data/eval/"
    - "data/parallel/"
    - "data/embeddings/"
    outs:
    - "translations/${stage}/"
    - "scores/${stage}/"
